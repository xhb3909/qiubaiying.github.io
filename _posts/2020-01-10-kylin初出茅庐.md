---
layout:     post
title:      kylin初出茅庐
date:       2020-01-10
author:     xhb
header-img: img/post-bg-ios9-web.jpg
catalog: true
sid: 20200110
tags:
    - kylin
---

# 初出茅庐
今天想给大家介绍一下我们国人的骄傲`kylin`。 最初由eBay公司开发并贡献至开源社区。目前`Kylin`已经成为Apache的顶级项目，
自Hadoop选取大象图标伊始，上百个项目，以动物居之者为多。而其中唯有Apache `Kylin` 来源中国。Apache `Kylin`是唯一一个来自中国的Apache顶级开源项目，
是我们国人的骄傲!

`麒麟出没，必有祥瑞`
![麒麟](https://pic.kuaizhan.com/g3/ff/a5/e13b-eb67-4ecc-b719-f762d36f956c49)

## `kylin`能够做什么
这是很多人比较关心的话题，`kylin`能够解决现有大数据的哪些痛点。
首先来看一下官方对`kylin`的定义:

```
Apache Kylin™是一个开源的分布式分析引擎，提供Hadoop之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，
最初由eBay Inc.开发并贡献至开源社区。

```

自从Hadoop诞生以来，大数据的存储和批处理问题得到了妥善解决，而如何高速地分析数据成为下一个挑战。于是各种'SQL-on-Hadoop'技术应运而生,以
Hive为代表, Impala、Spark SQL等紧随其后，主要技术就是大规模并行处理和列式存储。
大规模并行处理可以调用多台机器并行计算，用线性增加资源来换取计算时间的线性下降。列式存储则将记录按列存放，不仅在访问时可以只读取需要的列，
更可以利用存储设备连续读取的特点，大大提高读取的速率。这两项关键技术使得Hadoop上的SQL查询速度从小时级提高到了分钟级。
然而其实对于分钟级也是能够让人难以接受的，并且没有改变查询问题本身的时间复杂度，查询时间会随着数据的增多，时间会不断延长。比如查询1亿
条数据记录耗时一分钟，查询10亿条数据就需要10分钟。

`Apache Kylin`能够解决怎么样的痛点呢?
它的初衷就是解决千亿、万亿条记录的秒级查询问题。其中的关键就是打破查询时间随着数据量呈线性增长的这一规律.
仔细思考大数据`OLAP`，可以发现两个事实:
* 大数据查询一般是统计结果，多条记录经过聚合函数计算后的统计值。原始的记录则不是必须的。
* 聚合是按维度进行的，维度的聚合可能性是有限的。一般不随数据的膨胀而线性增长。

所以, `kylin`基于以上两点提出了一个新的可行性方案'预计算'，尽量多地预先计算聚合结果，在查询时刻也尽量使用与计算的结果得出查询结果，避免
直接扫描。

可以举一个例子，用SQL查询10月1日那天销量最高的商品

```sql
select item, sum(sell_amount) from sell_details where sell_date='2020-01-10' group by item order by sum(sell_amount) desc 

```

传统的方式，需要扫描所有的记录，找到10月1日的销售记录，然后按商品聚合销售额，最后排序返回。这种方式，随着数据量的增加，查询执行的时间可能会增加一倍。

预计算则会事先按维度[sell_date, item]计算SUM(sell_amount)并将其存储下来，在查询时找到10月1日的销售商品就可以直接排序
返回了。读取的记录数最大不超过维度[sell_date, item]的组合数。假设有一亿条交易记录只包含了一百万种商品，那么预计算之后就只有
100万条记录，大大减少了查询时的数据规模。

所以，'预计算'就是`Kylin`在'大规模并行处理'和'列式存储'之外，提供给大数据分析的第三个关键技术。

## `Apache Kylin`的工作原理
谈工作原理之前，需要先介绍一下维度(dimension)和度量(measure)这两个概念。
维度就是观察数据的角度。比如电商的销售数据，可以从时间的维度来观察，如图所示:
![时间图片](https://pic.kuaizhan.com/g3/02/89/41a0-7573-4fe2-839a-ab95f4f22d7b28)
也可以进一步细化从时间和地区的维度来观察
![时间地区图片](https://pic.kuaizhan.com/g3/9c/86/6dc3-a5ab-4a28-b60b-5b392299f0b342)
维度是一组离散的值，比如时间维度上的每一个独立的日期，或者商品维度上的每一件独立的商品。
统计时可以把维度值相同的记录聚合起来，应用聚合函数做累加、平均、去重复计数等聚合计算。

度量就是被聚合的统计值，就是聚合运算的结果。

* Cube 和 Cuboid
了解了维度和度量，我们就可以对数据表或者数据模型上的所有字段进行分类了，他们要么是维度，要么是度量(可以被聚合)。
于是就有了根据维度、度量做预计算的Cube理论。

给定一个数据模型，我们可以对其上所有维度进行组合。对于N个维度来说，所有组合的可能性有2的N次方。对每一种维度的组合。
将度量做聚合运算，运算的结果保存为一个物化视图，称为Cuboid。将所有维度组合的Cuboid作为一个整体，被称为Cube.
所以，一个Cube就是许多按维度聚合的物化视图的集合.

举一个例子。假定有一个电商的销售数据集，其中维度有时间(Time)、商品(Item)、地点(Location)和供应商(Supplier)，
度量有销售额(GMV)。那么，所有维度的组合既有2的4次方-- 16种。比如一维度 (1D)的组合有[Time][Item][Location][Supplier]
四种，二维度(2D)的组合有六种; 三维度(3D)的组合有四种; 最后，零维度(0D)和四维度(4D)的组合各有一种，共计16种组合.

计算Cuboid,就是按维度来聚合销售额(GMV)。如果用SQL来表达计算Cuboid[Time, Location]，那就是:
![物化视图](https://pic.kuaizhan.com/g3/80/9e/7e8e-7863-4f39-90fd-e21504f8597c65)
将计算的结果保存为物化视图，所有Cuboid物化视图的总称就是Cube了

`Apache Kylin`的工作原理就是对数据模型做Cube预计算，利用计算的结果加速查询。
过程如下:
1. 指定数据模型，定义维度和度量
2. 预计算Cube，计算所有Cuboid并将其保存为物化视图.
3. 执行查询时，读取Cuboid，进行加工运算产生查询结果.

## 技术架构
`Apache Kylin`的架构图如下所示:
![架构](https://pic.kuaizhan.com/g3/35/ba/9d32-b00d-490d-a742-0648e0a18a3680)

数据源在左侧，目前主要是hadoop、Hive、Kafka和RDBMS，其中保存着待分析的用户数据。根据元数据定义，下方构建
引擎从数据源中抽取数据，并构建cube。数据以关系表的形式输入。用户可以选择使用MapReduce或Spark进行构建。构建后的
Cube保存在右侧的存储引擎中，目前HBase是默认的存储引擎。

完成离线构建后，用户可以从上方查询系统发送SQL来进行查询分析。无论从哪个接口进入，最终SQL都会来到REST服务层，再转交给
查询引擎进行处理。

## 总结
这篇文章主要简单简述了`kylin`的基础原理。`kylin`巧妙地利用了预计算，把数据保存为物化视图，执行查询时，直接读取Cuboid，避免查询原数据。
查询时间不会随着数据规模的增加而程线性增加，而是与组合数有关。
